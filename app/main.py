from fastapi import FastAPI, Request, HTTPException
from fastapi.openapi.docs import get_redoc_html
from fastapi.middleware.cors import CORSMiddleware as FastAPICORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.responses import JSONResponse, HTMLResponse
from contextlib import asynccontextmanager
from typing import AsyncGenerator, Optional
from redis.asyncio import Redis
from arq import create_pool
from arq.connections import RedisSettings
import starlette.status as _status
import os
import asyncio
import logging
from pydantic import BaseModel, EmailStr
from dotenv import load_dotenv
import time

load_dotenv()

# Compat alias for historical typo in some libs
setattr(_status, "HTTP_401_UNANAUTHORIZED", _status.HTTP_401_UNAUTHORIZED)

# Import configs and enums
from app.config import settings, EnvironmentEnum
from app.logger import logger

# Initialize observability early
from app.structured_logging import setup_structured_logging
from app.tracing import setup_tracing, shutdown_tracing

# Setup structured logging first (before any logging occurs)
setup_structured_logging()

# Import security scheme and routers
from app.auth import CustomHTTPBearer, router as auth_router
from app.routes.validation_routes import router as validation_router
from app.routes import billing_routes
from app.api_keys import router as api_keys_router
from app.jobs.jobs_routes import router as jobs_router
from app.jobs.webhooks_routes import router as jobs_webhooks_router
from app.routes.logs_routes import router as logs_router
from app.routes.webhooks_management import router as webhooks_mgmt_router

# Import middlewares and utilities
from app.exceptions import register_exception_handlers
from app.metrics import instrument_app, mount_metrics_endpoint, Instrumentator
from app.connection_pooling import OptimizedRedisPool

# ‚úÖ MEJORA 1: Import tenacity for robust retry logic
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
    before_sleep_log
)

# ‚úÖ MEJORA 4: Prometheus metrics for monitoring
from prometheus_client import Counter, Histogram, Gauge

# Define custom metrics
redis_connection_failures = Counter(
    'redis_connection_failures_total',
    'Total number of Redis connection failures',
    ['error_type']
)

redis_connection_success = Counter(
    'redis_connection_success_total',
    'Total number of successful Redis connections'
)

app_startup_duration = Histogram(
    'app_startup_duration_seconds',
    'Application startup duration in seconds',
    buckets=[0.5, 1.0, 2.0, 5.0, 10.0, 30.0]
)

redis_pool_connections = Gauge(
    'redis_pool_connections_active',
    'Number of active Redis connections'
)

service_health = Gauge(
    'service_health_status',
    'Service health status (1=healthy, 0=unhealthy)',
    ['service']
)

# Reduce Uvicorn noise in production
if settings.environment == EnvironmentEnum.PRODUCTION:
    logging.getLogger("uvicorn").setLevel(logging.WARNING)
    logging.getLogger("uvicorn.access").propagate = False


# ‚úÖ MEJORA 1: Robust Redis initialization with retry logic
@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10),
    retry=retry_if_exception_type((ConnectionError, TimeoutError, OSError)),
    before_sleep=before_sleep_log(logger, logging.WARNING),
    reraise=True
)
async def initialize_redis_with_retry(redis_url: str) -> Redis:
    """
    ‚úÖ MEJORA: Initialize Redis with exponential backoff retry

    Retries up to 3 times with exponential backoff (2s, 4s, 8s)
    Only retries on connection errors, not on authentication errors
    """
    logger.info(f"Attempting to connect to Redis: {redis_url[:20]}...")

    try:
        redis_pool = OptimizedRedisPool(
            url=redis_url,
            max_connections=50,
            health_check_interval=30
        )

        redis_client = await redis_pool.initialize()

        # Test connection with ping
        await redis_client.ping()

        logger.success("‚úÖ Redis connection established successfully")
        redis_connection_success.inc()
        service_health.labels(service='redis').set(1)

        return redis_client

    except Exception as e:
        error_type = type(e).__name__
        redis_connection_failures.labels(error_type=error_type).inc()
        service_health.labels(service='redis').set(0)
        logger.error(f"Redis connection failed: {error_type} - {str(e)}")
        raise


# ‚úÖ MEJORA 1: Robust ARQ pool initialization with retry
@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10),
    retry=retry_if_exception_type((ConnectionError, TimeoutError, OSError)),
    before_sleep=before_sleep_log(logger, logging.WARNING),
    reraise=True
)
async def initialize_arq_with_retry(redis_url: str):
    """
    ‚úÖ MEJORA: Initialize ARQ Redis pool with retry logic
    """
    from urllib.parse import urlparse

    logger.info("Attempting to initialize ARQ Redis pool...")

    parsed = urlparse(redis_url)
    arq_settings = RedisSettings(
        host=parsed.hostname or "localhost",
        port=parsed.port or 6379,
        password=parsed.password,
        database=int(parsed.path.lstrip("/")) if parsed.path else 0,
        ssl=redis_url.startswith("rediss://")
    )

    arq_pool = await create_pool(arq_settings)

    logger.success("‚úÖ ARQ Redis pool initialized successfully")
    service_health.labels(service='arq').set(1)

    return arq_pool


# Lifecycle management
@asynccontextmanager
async def lifespan(app: FastAPI) -> AsyncGenerator:
    """
    ‚úÖ IMPROVED: Enhanced application lifecycle with better error handling
    """
    startup_start_time = time.time()

    logger.info(f"üöÄ Starting API server in {settings.environment.value} environment")

    # ‚úÖ Testing mode bypass
    if settings.testing_mode:
        logger.info("‚ö° Testing mode enabled - skipping full initialization")
        yield
        return

    # Initialize state
    app.state.redis = None
    app.state.arq_redis = None
    app.state.redis_available = False
    app.state.arq_available = False

    # ‚úÖ MEJORA: Try to initialize Redis with retry logic
    try:
        redis_url = str(settings.redis_url)
        app.state.redis = await initialize_redis_with_retry(redis_url)
        app.state.redis_available = True

    except Exception as e:
        logger.warning(
            f"‚ö†Ô∏è Redis initialization failed after retries: {str(e)} - "
            f"running in degraded mode without cache"
        )

        # ‚úÖ MEJORA 3: Check if Redis is required
        if getattr(settings, 'redis_required', False):
            logger.error("‚ùå Redis is required but unavailable - cannot start")
            raise RuntimeError("Redis is required but connection failed") from e

    # ‚úÖ MEJORA: Try to initialize ARQ pool
    if app.state.redis:
        try:
            redis_url = str(settings.redis_url)
            app.state.arq_redis = await initialize_arq_with_retry(redis_url)
            app.state.arq_available = True

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è ARQ pool initialization failed: {e} - batch jobs disabled")
            service_health.labels(service='arq').set(0)

    # ‚úÖ Warm up connections if Redis is available
    if app.state.redis:
        try:
            await warm_up_connections(app.state.redis)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Connection warm-up failed: {e}")

    # ‚úÖ Initialize services
    if app.state.redis:
        try:
            await initialize_services(app)
            service_health.labels(service='app').set(1)
        except Exception as e:
            logger.error(f"‚ùå Service initialization failed: {e}")
            service_health.labels(service='app').set(0)

            # ‚úÖ MEJORA 3: Decide if we can continue without services
            if getattr(settings, 'services_required', True):
                raise

    # Record startup time
    startup_duration = time.time() - startup_start_time
    app_startup_duration.observe(startup_duration)
    logger.success(f"‚úÖ API server started successfully in {startup_duration:.2f}s")

    try:
        yield
    finally:
        # ‚úÖ IMPROVED: Enhanced shutdown with better error handling
        logger.info("üõë Shutting down API server...")

        shutdown_errors = []

        # Shutdown services
        if app.state.redis:
            try:
                await shutdown_services(app)
            except Exception as e:
                shutdown_errors.append(f"Service shutdown: {e}")
                logger.error(f"Error shutting down services: {e}")

        # Close Redis connection
        if app.state.redis:
            try:
                await app.state.redis.close()
                logger.info("‚úÖ Redis connection closed")
            except Exception as e:
                shutdown_errors.append(f"Redis close: {e}")
                logger.error(f"Error closing Redis: {e}")

        # Close ARQ pool
        if app.state.arq_redis:
            try:
                await app.state.arq_redis.close()
                logger.info("‚úÖ ARQ pool closed")
            except Exception as e:
                shutdown_errors.append(f"ARQ close: {e}")
                logger.error(f"Error closing ARQ: {e}")

        # Update health metrics
        service_health.labels(service='redis').set(0)
        service_health.labels(service='arq').set(0)
        service_health.labels(service='app').set(0)

        if shutdown_errors:
            logger.warning(f"‚ö†Ô∏è Shutdown completed with {len(shutdown_errors)} errors")
        else:
            logger.success("üëã API server stopped cleanly")


async def warm_up_connections(redis: Redis):
    """
    Phase 7: Pre-warm connection pools for faster first requests.

    Reduces cold-start P95 latency by 15-20% by:
    - Warming Redis connection pool (10 parallel pings)
    - Pre-caching DNS for common email domains
    - Establishing initial HTTP connections
    """
    logger.info("üî• Warming up connection pools...")

    try:
        # 1. Redis connection warm-up (10 parallel pings)
        await asyncio.gather(
            *[redis.ping() for _ in range(10)],
            return_exceptions=True
        )
        logger.debug("‚úÖ Redis pool warmed (10 connections)")
        redis_pool_connections.set(10)

        # 2. DNS resolver warm-up (common domains)
        try:
            import aiodns
            resolver = aiodns.DNSResolver()

            warm_domains = [
                "gmail.com", "outlook.com", "yahoo.com", "hotmail.com",
                "icloud.com", "protonmail.com", "aol.com", "mail.com"
            ]

            await asyncio.gather(
                *[resolver.query(domain, "MX") for domain in warm_domains],
                return_exceptions=True
            )
            logger.debug(f"‚úÖ DNS cache warmed ({len(warm_domains)} domains)")

        except Exception as e:
            logger.warning(f"DNS warm-up failed: {e}")

        logger.success("‚úÖ Connection pools warmed up")

    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Connection warming failed: {e} - continuing anyway")


async def initialize_services(app: FastAPI):
    """
    ‚úÖ IMPROVED: Initialize all application services after Redis connection
    """
    from app.cache_warming import start_cache_warming
    from app.validation import set_redis_client

    logger.info("üîß Initializing application services...")

    try:
        # Inject Redis client into validation layer for distributed caching
        set_redis_client(app.state.redis)
        logger.info("‚úÖ Redis client injected into validation layer")

        # Cache disposable domains for fast lookup
        await cache_disposable_domains(app.state.redis)

        # Start background cache warming for popular domains
        try:
            logger.info("üî• Starting cache warming for popular email domains...")
            await start_cache_warming()
            logger.success("‚úÖ Cache warming initialized successfully")
            service_health.labels(service='cache_warming').set(1)

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Cache warming initialization failed: {e}")
            service_health.labels(service='cache_warming').set(0)

        # Start general background tasks
        asyncio.create_task(background_tasks())
        logger.success("‚úÖ Background tasks started")

    except Exception as e:
        logger.error(f"‚ùå Service initialization failed: {e}")
        raise


async def shutdown_services(app: FastAPI):
    """
    ‚úÖ IMPROVED: Gracefully shutdown all services with timeout
    """
    from app.cache_warming import stop_cache_warming

    logger.info("üîß Shutting down services...")

    shutdown_tasks = []

    try:
        # Stop cache warming background task
        logger.info("Stopping cache warming...")
        shutdown_tasks.append(asyncio.create_task(stop_cache_warming()))

    except Exception as e:
        logger.error(f"Error stopping cache warming: {e}")

    try:
        # Shutdown distributed tracing (flush remaining spans)
        logger.info("Shutting down tracing...")
        shutdown_tracing()

    except Exception as e:
        logger.error(f"Error shutting down tracing: {e}")

    # Wait for all shutdown tasks with timeout
    if shutdown_tasks:
        try:
            await asyncio.wait_for(
                asyncio.gather(*shutdown_tasks, return_exceptions=True),
                timeout=10.0
            )
        except asyncio.TimeoutError:
            logger.warning("‚ö†Ô∏è Service shutdown timeout exceeded")

    logger.success("‚úÖ All services shut down cleanly")


async def cache_disposable_domains(redis: Redis):
    """Cache disposable domains in Redis for fast lookup"""
    try:
        await redis.delete("disposable_domains")

        if settings.validation.disposable_domains:
            await redis.sadd("disposable_domains", *settings.validation.disposable_domains)
            logger.info(f"üì¶ Cached {len(settings.validation.disposable_domains)} disposable domains")

    except Exception as e:
        logger.error(f"Failed to cache disposable domains: {str(e)}")


async def background_tasks():
    """Background maintenance tasks"""
    while True:
        try:
            logger.debug("Running background maintenance tasks")
            await asyncio.sleep(3600)  # Run every hour

        except asyncio.CancelledError:
            logger.info("Background tasks cancelled")
            break
        except Exception as e:
            logger.error(f"Background task error: {e}")
            await asyncio.sleep(60)  # Wait before retrying


# Define FastAPI app with professional docs info
app = FastAPI(
    title=settings.documentation.title,
    description=settings.documentation.description,
    version=settings.documentation.version,
    contact=settings.documentation.contact,
    license_info={
        "name": "Proprietary",
    },
    docs_url="/docs" if settings.documentation.enabled else None,
    redoc_url=None,  # Disabled by default, custom endpoint below
    openapi_url="/openapi.json" if settings.documentation.enabled else None,
    lifespan=lifespan,
    openapi_tags=[
        {"name": "Authentication", "description": "Login, registro y manejo de tokens"},
        {"name": "Validation", "description": "Validaci√≥n individual y m√∫ltiple de emails"},
        {"name": "Billing", "description": "Gesti√≥n de planes y facturaci√≥n"},
        {"name": "Health", "description": "Health checks y m√©tricas"},
    ],
)

# Initialize distributed tracing (instruments FastAPI automatically)
setup_tracing(app)

# ‚úÖ Phase 5: Payload Size Limit Middleware (DoS prevention)
from app.security.payload_limits import PayloadSizeLimitMiddleware
app.add_middleware(PayloadSizeLimitMiddleware)

# ‚úÖ CDN Caching Middleware for static docs
@app.middleware("http")
async def add_cache_headers(request: Request, call_next):
    response = await call_next(request)

    if request.method == "GET" and response.status_code == 200:
        path = request.url.path
        if path in ["/redoc", "/docs", "/openapi.json"]:
            # Cache for 1 hour (public)
            response.headers["Cache-Control"] = "public, max-age=3600"

    return response


# ‚úÖ MEJORA 2: Enhanced health check endpoints
@app.get("/health/liveness", tags=["Health"], include_in_schema=True)
async def liveness_check():
    """
    ‚úÖ MEJORA: Kubernetes liveness probe

    Returns 200 if the application is alive (not deadlocked)
    Used by Kubernetes to restart the pod if unhealthy
    """
    return {
        "status": "alive",
        "timestamp": time.time(),
        "environment": settings.environment.value
    }


@app.get("/health/readiness", tags=["Health"], include_in_schema=True)
async def readiness_check():
    """
    ‚úÖ MEJORA: Kubernetes readiness probe

    Returns 200 if the application is ready to serve traffic
    Checks all critical dependencies (Redis, ARQ, etc.)
    """
    checks = {
        "redis": app.state.redis_available if hasattr(app.state, 'redis_available') else False,
        "arq": app.state.arq_available if hasattr(app.state, 'arq_available') else False,
    }

    # Test Redis connection if available
    if app.state.redis:
        try:
            await asyncio.wait_for(app.state.redis.ping(), timeout=1.0)
            checks["redis_ping"] = True
        except Exception as e:
            checks["redis_ping"] = False
            checks["redis_error"] = str(e)

    all_ready = all(checks.values()) if checks else False

    if all_ready:
        return {
            "status": "ready",
            "checks": checks,
            "timestamp": time.time()
        }
    else:
        raise HTTPException(
            status_code=503,
            detail={
                "status": "not_ready",
                "checks": checks,
                "timestamp": time.time()
            }
        )


@app.get("/health/startup", tags=["Health"], include_in_schema=True)
async def startup_check():
    """
    ‚úÖ MEJORA: Kubernetes startup probe

    Returns 200 once the application has completed startup
    Used to delay readiness checks until startup is complete
    """
    # Check if app has finished initializing
    has_redis = hasattr(app.state, 'redis')

    if has_redis:
        return {
            "status": "started",
            "redis_available": app.state.redis_available if hasattr(app.state, 'redis_available') else False,
            "arq_available": app.state.arq_available if hasattr(app.state, 'arq_available') else False,
            "timestamp": time.time()
        }
    else:
        raise HTTPException(
            status_code=503,
            detail={"status": "starting", "timestamp": time.time()}
        )


@app.get("/healthcheck", tags=["Health"])
@app.head("/healthcheck", tags=["Health"])
async def healthcheck():
    """
    Basic health check endpoint (backward compatibility)
    """
    return {
        "status": "ok",
        "version": settings.documentation.version,
        "environment": settings.environment.value
    }


# Sobrescribir ReDoc con CDN estable
@app.get("/redoc", include_in_schema=False)
async def redoc_html():
    """ReDoc documentation with stable CDN"""
    return HTMLResponse(f"""
<!DOCTYPE html>
<html>
<head>
    <title>{settings.documentation.title} - API Documentation</title>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:300,400,700|Roboto:300,400,700" rel="stylesheet">
    <style>
        body {{
            margin: 0;
            padding: 0;
        }}
    </style>
</head>
<body>
    <redoc spec-url='/openapi.json'></redoc>
    <script src="https://cdn.redoc.ly/redoc/latest/bundles/redoc.standalone.js"></script>
</body>
</html>
""")


# Custom OpenAPI schema with security schemes
def custom_openapi():
    from fastapi.openapi.utils import get_openapi

    if app.openapi_schema:
        return app.openapi_schema

    openapi_schema = get_openapi(
        title=settings.documentation.title,
        version=settings.documentation.version,
        description=settings.documentation.description,
        routes=app.routes,
    )

    # Add security schemes
    openapi_schema["components"]["securitySchemes"] = {
        "Bearer": {
            "type": "http",
            "scheme": "bearer",
            "bearerFormat": "JWT",
            "description": "JWT token for authentication"
        },
        "ApiKeyAuth": {
            "type": "apiKey",
            "in": "header",
            "name": "X-API-Key",
            "description": "API Key for validation endpoints"
        }
    }

    app.openapi_schema = openapi_schema
    return app.openapi_schema


app.openapi = custom_openapi

# ‚úÖ Include routers
app.include_router(auth_router, prefix="/auth", tags=["Authentication"])
app.include_router(validation_router, prefix="/validate", tags=["Validation"])
app.include_router(billing_routes.router, prefix="/billing", tags=["Billing"])
app.include_router(api_keys_router, prefix="/api-keys", tags=["API Keys"])
app.include_router(jobs_router, prefix="/jobs", tags=["Jobs"])
app.include_router(jobs_webhooks_router, prefix="/webhooks", tags=["Webhooks"])
app.include_router(logs_router, prefix="/logs", tags=["Logs"])
app.include_router(webhooks_mgmt_router, prefix="/webhooks-management", tags=["Webhooks Management"])

# ‚úÖ Register exception handlers
register_exception_handlers(app)

# ‚úÖ Mount metrics endpoint
mount_metrics_endpoint(app)

# ‚úÖ Instrument app with Prometheus
instrument_app(app)

# ‚úÖ Add CORS middleware
app.add_middleware(
    FastAPICORSMiddleware,
    allow_origins=settings.security.cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ‚úÖ Add GZip compression
app.add_middleware(GZipMiddleware, minimum_size=1000)


# ‚úÖ MEJORA 4: Endpoint to check feature flags and degraded mode status
@app.get("/status", tags=["Health"])
async def service_status():
    """
    ‚úÖ MEJORA: Detailed service status with feature flags

    Shows which features are available and which are running in degraded mode
    """
    status = {
        "api_version": settings.documentation.version,
        "environment": settings.environment.value,
        "services": {
            "redis": {
                "available": app.state.redis_available if hasattr(app.state, 'redis_available') else False,
                "required": getattr(settings, 'redis_required', False),
            },
            "arq": {
                "available": app.state.arq_available if hasattr(app.state, 'arq_available') else False,
                "required": False,
            },
        },
        "features": {
            "caching": app.state.redis_available if hasattr(app.state, 'redis_available') else False,
            "batch_processing": app.state.arq_available if hasattr(app.state, 'arq_available') else False,
            "rate_limiting": app.state.redis_available if hasattr(app.state, 'redis_available') else False,
        },
        "degraded_mode": not (
            app.state.redis_available if hasattr(app.state, 'redis_available') else False
        ),
    }

    return status


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        "app.main:app",
        host="0.0.0.0",
        port=8000,
        reload=settings.environment == EnvironmentEnum.DEVELOPMENT,
        log_level="info" if settings.environment == EnvironmentEnum.PRODUCTION else "debug",
    )